{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f28a4-b936-429c-90a6-03095eb4b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from model_clf import MrModel, MrSpecialModel\n",
    "from dataloader_clf import create_data_loaders\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9823b93-fcd3-4dc6-9595-e0cf5f9e5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dataset loading and splitting\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Model setup\n",
    "model1 = MrModel(num_classes=num_classes).to(device)        # Standard Convolutional Layers\n",
    "model2 = MrSpecialModel(num_classes=num_classes).to(device) # Vector Based Layers\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=learning_rate)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training function\n",
    "def train_and_evaluate(model, optimizer, train_loader, val_loader, num_epochs, model_name):\n",
    "    model_metrics = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        model_metrics['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        model_metrics['val_loss'].append(avg_val_loss)\n",
    "        model_metrics['val_accuracy'].append(val_accuracy)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Save the model state and metrics\n",
    "    torch.save(model.state_dict(), f'{model_name}_state_dict.pth')\n",
    "    with open(f'{model_name}_metrics.json', 'w') as f:\n",
    "        json.dump(model_metrics, f)\n",
    "\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ee527-4f5f-4fdd-8a9e-01ca2b641dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both models\n",
    "train_loader, val_loader = create_data_loaders(batch_size=16)\n",
    "#metrics1 = train_and_evaluate(model1, optimizer1, train_loader, val_loader, num_epochs, 'Standard')\n",
    "train_loader, val_loader = create_data_loaders(batch_size=16) # Adjusted for memory issues\n",
    "metrics2 = train_and_evaluate(model2, optimizer2, train_loader, val_loader, num_epochs, 'Custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4138850-ae9e-435a-9564-71a7f7741053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for training losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, metrics1['train_loss'], label='Standard Model Training Loss', marker='o')\n",
    "plt.plot(epochs, metrics2['train_loss'], label='Custom Model Training Loss', marker='o')\n",
    "plt.title('Training Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for validation losses\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, metrics1['val_loss'], label='Standard Model Validation Loss', marker='o')\n",
    "plt.plot(epochs, metrics2['val_loss'], label='Custom Model Validation Loss', marker='o')\n",
    "plt.title('Validation Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6142f8b-098f-4cf1-865b-aa4c4146cc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
